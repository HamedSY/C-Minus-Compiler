# -*- coding: utf-8 -*-
"""Parser.ipynb

Automatically generated by Colab.

Hamed Saboor 400105082
Maryam Shiran 400109446

## Scanner
"""

# Scanner

"""DFA


"""
#import semantic_checks

# Global variables to store DFA information
num_states = 15
transitions = [[] for _ in range(num_states)]
accept_states = [False] * num_states

# accepting states
accept_states[1] = True  # Symbol
accept_states[2] = True  # Symbol
accept_states[6] = True  # Symbol
accept_states[7] = True  # Number (NUM)
accept_states[9] = True  # Comment
accept_states[13] = True  # ID/Keyword
accept_states[12] = True  # Whitespace (to be ignored)

# Character groups
digit = "0123456789"
sym = "[](){}+-*<;:,="
whitespace = " \n\f\r\v\t"
English_alphabet = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ"

# Define DFA transitions manually
transitions[0].append(("*", True, 14))
transitions[14].append((sym + digit + whitespace + English_alphabet, False, 1))
transitions[0].append(("[](){}+-<;:,", True, 1))
transitions[0].append(("=", True, 3))
transitions[3].append(("=", True, 1))  # '==' symbol
transitions[3].append(("/\0" + sym + digit + whitespace + English_alphabet, False, 2))  # '=' symbol
transitions[0].append((digit, True, 4))  # Start of a number
transitions[4].append((digit, True, 4))  # Continue reading digits
transitions[4].append((sym + whitespace + "/\0", False, 7))  # Finalize the number
transitions[0].append(("/", True, 6))  # Start of comment
transitions[6].append(("*", True, 5))  # Block comment start '/*'
transitions[5].append(('0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\'()+,-./:;<=>?@['
                       '\\]^_`{|}~ \n\t\r\x0b\x0c', True, 5))  # Inside comment
transitions[6].append(("/", True, 10))  # Line comment start '//'
transitions[10].append(('0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!"#$%&\'()*+,-./:;<=>?@['
                        '\\]^_`{|}~ \t\r\x0b\x0c', True, 10))  # Inside line comment
transitions[10].append(("\n\0", True, 9))  # End of line comment
transitions[5].append(("*", True, 8))  # Block comment end '*/'
transitions[8].append(("*", True, 8))  # More stars in block comment
transitions[8].append(("[](){}+-<;:,=" + digit + whitespace + English_alphabet, True, 5))  # Inside comment
transitions[8].append(("/", True, 9))  # End of block comment
transitions[0].append((English_alphabet, True, 11))  # Start of identifier
transitions[11].append((digit + English_alphabet, True, 11))  # Continue reading identifier
transitions[11].append(("/\0" + sym + whitespace, False, 13))  # Finalize identifier
transitions[0].append((whitespace, True, 12))  # Whitespace


def get_next_state(current_state, character):
    for (characters, included, next_state) in transitions[current_state]:
        if character in characters:
            return next_state, included
    return None, None


KEYWORDS = {"break", "else", "if", "endif", "int", "while", "return", "void"}


class Scanner:
    def __init__(self, file_name):
        self.index = 0
        self.file = open(file_name, 'r')
        self.input_text = self.file.read()
        self.current_line = 1

    def get_next_token(self):
        current_state = 0
        lexeme = ""

        while self.index < len(self.input_text):
            char = self.input_text[self.index]
            next_state, is_included = get_next_state(current_state, char)

            if next_state is None:
                error_found = False
                if accept_states[current_state]:
                    if current_state == 1 or current_state == 2 or current_state == 6:  # Symbol found
                        return lexeme, "SYMBOL", lexeme, self.current_line
                    elif current_state == 7:  # Number found
                        return "NUM", "NUM", lexeme, self.current_line
                    elif current_state == 13:  # ID or keyword found
                        #tables.get_symbol_table().add_symbol(('ID', lexeme))
                        if lexeme in KEYWORDS:
                            return lexeme, "KEYWORD", lexeme, self.current_line
                        else:
                            return "ID", "ID", lexeme, self.current_line
                    elif current_state == 12:  # Whitespace found
                        pass  # Ignore
                else:
                    error_found = True

                # Reset for the next token
                lexeme = ""
                current_state = 0
                if char in whitespace or error_found:
                    self.index += 1
                    if char == '\n':
                        self.current_line += 1
                continue

            if is_included:
                lexeme += char
                self.index += 1
            current_state = next_state

            if lexeme == '\n':
                self.current_line += 1

        self.file.close()
        return "$", "EOF", "$", self.current_line


"""## Dicts"""
# Here are the dictionaries we have extracted from the site shared on the homework's document.

first_sets = {
    'Program': ['$', 'int', 'void', 'ε'],
    'DeclarationList': ['int', 'void', 'ε'],
    'Declaration': ['int', 'void'],
    'DeclarationInitial': ['int', 'void'],
    'DeclarationPrime': [';', '[', '('],
    'VarDeclarationPrime': [';', '['],
    'FunDeclarationPrime': ['('],
    'TypeSpecifier': ['int', 'void'],
    'Params': ['int', 'void'],
    'ParamList': [',', 'ε'],
    'Param': ['int', 'void'],
    'ParamPrime': ['[', 'ε'],
    'CompoundStmt': ['{'],
    'StatementList': ['ID', ';', 'NUM', '(', '{', 'break', 'if', 'while', 'return', '+', '-', 'ε'],
    'Statement': ['ID', ';', 'NUM', '(', '{', 'break', 'if', 'while', 'return', '+', '-'],
    'ExpressionStmt': ['ID', ';', 'NUM', '(', 'break', '+', '-'],
    'SelectionStmt': ['if'],
    'ElseStmt': ['endif', 'else'],
    'IterationStmt': ['while'],
    'ReturnStmt': ['return'],
    'ReturnStmtPrime': ['ID', ';', 'NUM', '(', '+', '-'],
    'Expression': ['ID', 'NUM', '(', '+', '-'],
    'B': ['[', '(', '=', '<', '==', '+', '-', '*', '/', 'ε'],
    'H': ['=', '<', '==', '+', '-', '*', '/', 'ε'],
    'SimpleExpressionZegond': ['NUM', '(', '+', '-'],
    'SimpleExpressionPrime': ['(', '<', '==', '+', '-', '*', '/', 'ε'],
    'C': ['<', '==', 'ε'],
    'Relop': ['<', '=='],
    'AdditiveExpression': ['ID', 'NUM', '(', '+', '-'],
    'AdditiveExpressionPrime': ['(', '+', '-', '*', '/', 'ε'],
    'AdditiveExpressionZegond': ['NUM', '(', '+', '-'],
    'D': ['+', '-', 'ε'],
    'Addop': ['+', '-'],
    'Term': ['ID', 'NUM', '(', '+', '-'],
    'TermPrime': ['(', '*', '/', 'ε'],
    'TermZegond': ['NUM', '(', '+', '-'],
    'G': ['*', '/', 'ε'],
    'Mulop': ['*', '/'],
    'SignedFactor': ['ID', 'NUM', '(', '+', '-'],
    'SignedFactorPrime': ['(', 'ε'],
    'SignedFactorZegond': ['NUM', '(', '+', '-'],
    'Factor': ['ID', 'NUM', '('],
    'VarCallPrime': ['[', '(', 'ε'],
    'VarPrime': ['[', 'ε'],
    'FactorPrime': ['(', 'ε'],
    'FactorZegond': ['NUM', '('],
    'Args': ['ID', 'NUM', '(', '+', '-', 'ε'],
    'ArgList': ['ID', 'NUM', '(', '+', '-'],
    'ArgListPrime': [',', 'ε']
}

follow_sets = {
    'Program': ['$'],
    'DeclarationList': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'while', 'return', '+', '-', '$'],
    'Declaration': ['ID', ';', 'NUM', '(', 'int', 'void', '{', '}', 'break', 'if', 'while', 'return', '+', '-', '$'],
    'DeclarationInitial': [';', '[', '(', ')', ','],
    'DeclarationPrime': ['ID', ';', 'NUM', '(', 'int', 'void', '{', '}', 'break', 'if', 'while', 'return', '+', '-',
                         '$'],
    'VarDeclarationPrime': ['ID', ';', 'NUM', '(', 'int', 'void', '{', '}', 'break', 'if', 'while', 'return', '+', '-',
                            '$'],
    'FunDeclarationPrime': ['ID', ';', 'NUM', '(', 'int', 'void', '{', '}', 'break', 'if', 'while', 'return', '+', '-',
                            '$'],
    'TypeSpecifier': ['ID'],
    'Params': [')'],
    'ParamList': [')'],
    'Param': [')', ','],
    'ParamPrime': [')', ','],
    'CompoundStmt': ['ID', ';', 'NUM', '(', 'int', 'void', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return',
                     '+', '-', '$'],
    'StatementList': ['}'],
    'Statement': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'ExpressionStmt': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'SelectionStmt': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'ElseStmt': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'IterationStmt': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'ReturnStmt': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'ReturnStmtPrime': ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'endif', 'else', 'while', 'return', '+', '-'],
    'Expression': [';', ']', ')', ','],
    'B': [';', ']', ')', ','],
    'H': [';', ']', ')', ','],
    'SimpleExpressionZegond': [';', ']', ')', ','],
    'SimpleExpressionPrime': [';', ']', ')', ','],
    'C': [';', ']', ')', ','],
    'Relop': ['ID', 'NUM', '(', '+', '-'],
    'AdditiveExpression': [';', ']', ')', ','],
    'AdditiveExpressionPrime': [';', ']', ')', ',', '<', '=='],
    'AdditiveExpressionZegond': [';', ']', ')', ',', '<', '=='],
    'D': [';', ']', ')', ',', '<', '=='],
    'Addop': ['ID', 'NUM', '(', '+', '-'],
    'Term': [';', ']', ')', ',', '<', '==', '+', '-'],
    'TermPrime': [';', ']', ')', ',', '<', '==', '+', '-'],
    'TermZegond': [';', ']', ')', ',', '<', '==', '+', '-'],
    'G': [';', ']', ')', ',', '<', '==', '+', '-'],
    'Mulop': ['ID', 'NUM', '(', '+', '-'],
    'SignedFactor': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'SignedFactorPrime': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'SignedFactorZegond': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'Factor': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'VarCallPrime': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'VarPrime': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'FactorPrime': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'FactorZegond': [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    'Args': [')'],
    'ArgList': [')'],
    'ArgListPrime': [')']
}

predict_sets = {
    1: ['int', 'void', '$'],
    2: ['int', 'void'],
    3: ['ID', ';', 'NUM', '(', '{', '}', 'break', 'if', 'while', 'return', '+', '-', '$'],
    4: ['int', 'void'],
    5: ['int', 'void'],
    6: ['('],
    7: [';', '['],
    8: [';'],
    9: ['['],
    10: ['('],
    11: ['int'],
    12: ['void'],
    13: ['int'],
    14: ['void'],
    15: [','],
    16: [')'],
    17: ['int', 'void'],
    18: ['['],
    19: [')', ','],
    20: ['{'],
    21: ['ID', ';', 'NUM', '(', '{', 'break', 'if', 'while', 'return', '+', '-'],
    22: ['}'],
    23: ['ID', ';', 'NUM', '(', 'break', '+', '-'],
    24: ['{'],
    25: ['if'],
    26: ['while'],
    27: ['return'],
    28: ['ID', 'NUM', '(', '+', '-'],
    29: ['break'],
    30: [';'],
    31: ['if'],
    32: ['endif'],
    33: ['else'],
    34: ['while'],
    35: ['return'],
    36: [';'],
    37: ['ID', 'NUM', '(', '+', '-'],
    38: ['NUM', '(', '+', '-'],
    39: ['ID'],
    40: ['='],
    41: ['['],
    42: [';', ']', '(', ')', ',', '<', '==', '+', '-', '*', '/'],
    43: ['='],
    44: [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    45: ['NUM', '(', '+', '-'],
    46: [';', ']', '(', ')', ',', '<', '==', '+', '-', '*', '/'],
    47: ['<', '=='],
    48: [';', ']', ')', ','],
    49: ['<'],
    50: ['=='],
    51: ['ID', 'NUM', '(', '+', '-'],
    52: [';', ']', '(', ')', ',', '<', '==', '+', '-', '*', '/'],
    53: ['NUM', '(', '+', '-'],
    54: ['+', '-'],
    55: [';', ']', ')', ',', '<', '=='],
    56: ['+'],
    57: ['-'],
    58: ['ID', 'NUM', '(', '+', '-'],
    59: [';', ']', '(', ')', ',', '<', '==', '+', '-', '*', '/'],
    60: ['NUM', '(', '+', '-'],
    61: ['*', '/'],
    62: [';', ']', ')', ',', '<', '==', '+', '-'],
    63: ['*'],
    64: ['/'],
    65: ['+'],
    66: ['-'],
    67: ['ID', 'NUM', '('],
    68: [';', ']', '(', ')', ',', '<', '==', '+', '-', '*', '/'],
    69: ['+'],
    70: ['-'],
    71: ['NUM', '('],
    72: ['('],
    73: ['ID'],
    74: ['NUM'],
    75: ['('],
    76: [';', '[', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    77: ['['],
    78: [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    79: ['('],
    80: [';', ']', ')', ',', '<', '==', '+', '-', '*', '/'],
    81: ['('],
    82: ['NUM'],
    83: ['ID', 'NUM', '(', '+', '-'],
    84: [')'],
    85: ['ID', 'NUM', '(', '+', '-'],
    86: [','],
    87: [')']
}

"""## Parser"""

from anytree import RenderTree, Node



grammar = [
    {"Program": ["DeclarationList","$","#main_starter"]},
    {"DeclarationList": ["Declaration", "DeclarationList"]},
    {"DeclarationList": []},
    {"Declaration": ["DeclarationInitial", "DeclarationPrime"]},
    {"DeclarationInitial": [ "TypeSpecifier", "#put_id", "ID"]},
    {"DeclarationPrime": [ "FunDeclarationPrime"]},
    {"DeclarationPrime": ["VarDeclarationPrime"]},
    {"VarDeclarationPrime": ["#none_array_declaration", ";"]},
    {"VarDeclarationPrime": ["[","#array_declaration", "NUM", "]", ";"]},
    {"FunDeclarationPrime": ["#fun_declaration","(", "Params", ")","#save_stack_frame", "CompoundStmt", "#fun_declaration_end"]},
    {"TypeSpecifier": ["#type_specifier","int"]},
    {"TypeSpecifier": ["#type_specifier","void"]},
    {"Params": ["#type_specifier","int", "#put_id", "ID", "ParamPrime", "ParamList"]},
    {"Params": ["void"]},
    {"ParamList": [",", "Param", "ParamList"]},
    {"ParamList": []},
    {"Param": ["DeclarationInitial", "ParamPrime"]},
    {"ParamPrime": [ "[","#param_type_array", "]"]},
    {"ParamPrime": ["#param_type_n_array"]},
    {"CompoundStmt": ["{", "DeclarationList", "StatementList", "}"]},
    {"StatementList": ["Statement", "StatementList"]},
    {"StatementList": []},
    {"Statement": ["ExpressionStmt"]},
    {"Statement": ["CompoundStmt"]},
    {"Statement": [ "SelectionStmt"]},
    {"Statement": [ "IterationStmt"]},
    {"Statement": ["ReturnStmt"]},
    {"ExpressionStmt": ["Expression","#pop", ";"]},
    {"ExpressionStmt": [ "break", "#save_break",";"]},
    {"ExpressionStmt": [";"]},
    {"SelectionStmt": ["if", "(", "Expression", ")","#save" , "Statement",  "ElseStmt"]},
    {"ElseStmt": ["endif","#jpf"]},
    {"ElseStmt": ["else","#jpf_save" ,"Statement","#jp" ,"endif"]},
    {"IterationStmt": ["while","#label", "(", "Expression", ")","#save" , "Statement","#jpfw", "#while"]},
    {"ReturnStmt": ["return", "ReturnStmtPrime"]},
    {"ReturnStmtPrime": [ ";","#return_void"]},
    {"ReturnStmtPrime": [ "Expression","#return_value", ";"]},
    {"Expression": ["SimpleExpressionZegond"]},
    {"Expression": ["#pid", "ID", "B"]},
    {"B": ["=",  "Expression","#assign"]},
    {"B": ["[", "Expression", "]", "#array_index", "H"]},
    {"B": ["SimpleExpressionPrime"]},
    {"H": ["=",  "Expression","#assign"]},
    {"H": ["G", "D", "C"]},
    {"SimpleExpressionZegond": ["AdditiveExpressionZegond", "C"]},
    {"SimpleExpressionPrime": ["AdditiveExpressionPrime", "C"]},
    {"C": ["#save_operation","Relop",  "AdditiveExpression", "#do_operation"]},
    {"C": []},
    {"Relop": ["<"]},
    {"Relop": ["=="]},
    {"AdditiveExpression": ["Term", "D"]},
    {"AdditiveExpressionPrime": ["TermPrime", "D"]},
    {"AdditiveExpressionZegond": ["TermZegond", "D"]},
    {"D": ["#save_operation","Addop",  "Term", "#do_operation", "D"]},
    {"D": []},
    {"Addop": ["+"]},
    {"Addop": ["-"]},
    {"Term": ["SignedFactor", "G"]},
    {"TermPrime": ["SignedFactorPrime", "G"]},
    {"TermZegond": ["SignedFactorZegond", "G"]},
    {"G": ["#save_operation","Mulop",  "SignedFactor", "#do_operation", "G"]},
    {"G": []},
    {"Mulop": ["*"]},
    {"Mulop": ["/"]},
    {"SignedFactor": ["+", "Factor"]},
    {"SignedFactor": ["-", "Factor"]},
    {"SignedFactor": ["Factor"]},
    {"SignedFactorPrime": ["FactorPrime"]},
    {"SignedFactorZegond": ["+", "Factor"]},
    {"SignedFactorZegond": ["-", "Factor"]},
    {"SignedFactorZegond": ["FactorZegond"]},
    {"Factor": ["(", "Expression", ")"]},
    {"Factor": ["#pid", "ID", "VarCallPrime"]},
    {"Factor": ["#push","NUM"]},
    {"VarCallPrime": ["(", "#start_args", "Args", ")" ,"#call_function"]},
    {"VarCallPrime": ["VarPrime"]},
    {"VarPrime": ["[", "Expression", "#array_index", "]"]},
    {"VarPrime": []},
    {"FactorPrime": ["(", "#start_args", "Args",  ")", "#call_function"]},
    {"FactorPrime": []},
    {"FactorZegond": ["(", "Expression", ")"]},
    {"FactorZegond": ["#push","NUM"]},
    {"Args": ["ArgList"]},
    {"Args": []},
    {"ArgList": ["Expression", "#fill_record", "ArgListPrime"]},
    {"ArgListPrime": [",", "Expression","#fill_record", "ArgListPrime"]},
    {"ArgListPrime": []},

]

# columns of the parsing table
cls = {
    ";",
    "break",
    "if",
    "endif",
    "else",
    "while",
    "return",
    "ID",
    "NUM",
    "<",
    "==",
    "+",
    "-",
    "*",
    "/",
    "(",
    ")",
    "[",
    "]",
    "{",
    "}",
    "int",
    "void",
    "=",
    "$",
    ","
}
non_terminals = {list(rule.keys())[0] for rule in grammar}

# Create a Scanner
scanner = Scanner("input.txt")

# Parsing table
# we make the parsing table as described below:
parsing_table = {row: {cl: None for cl in cls} for row in non_terminals}


def construct_parsing_table():
    for non_terminal in non_terminals:

        for i, rule in enumerate(grammar):  # Iterate through grammar rules

            if non_terminal == list(rule.keys())[0]:  # Check if the rule's LHS matches the non-terminal
                for cl in predict_sets[i + 1]:  # Iterate through terminals in the predictive set
                    parsing_table[non_terminal][cl] = i  # Map the rule index to the terminal
                    # the reason for the disparacy between i and i+1 is that the list and enumerate index start from 0, whereas
                    # the prediction sets are indexed starting from 1

        # we also add the synch entries as disscussed on page 15th of lecture note 5
        for cl in cls:
            if parsing_table[non_terminal][cl] is None and cl in follow_sets[non_terminal]:
                parsing_table[non_terminal][cl] = "synch"
            if parsing_table[non_terminal][cl] is None and cl in first_sets[non_terminal]:
                parsing_table[non_terminal][cl] = "synch"

            # Construct the parsing table


construct_parsing_table()

syntax_errors = []


def panic_mode_recovery(parsstack, lookahead, line_number, top_symbol=None, top_node=None, token_type=None, lexeme=None):
    # panic mode will diagnose the agenda along with documenting the correspong error. later based on the agenda, the correct action will be done.

    # reaching end of the input, but having the stack still non-empty

    if lookahead == "$" and len(parsstack) > 1:
        syntax_errors.append(f"#{line_number} : syntax error, Unexpected EOF")
        return lookahead, top_symbol, top_node, token_type, lexeme, "EOF"

    if top_symbol in non_terminals:
        # Check if parsing table entry is "synch"
        if parsing_table.get(top_symbol, {}).get(lookahead) == "synch":
            syntax_errors.append(f"#{line_number} : syntax error, missing {top_symbol}")
            return lookahead, top_symbol, top_node, token_type, lexeme, "non-terminal insert"


        else:
            # Skip tokens until a valid entry is found in the parsing table
            syntax_errors.append(f"#{line_number} : syntax error, illegal {lookahead}")
            return lookahead, top_symbol, top_node, token_type, lexeme, "lookahead skip"

    # If top_symbol is a terminal
    if top_symbol in cls:
        if top_symbol != lookahead:
            syntax_errors.append(f"#{line_number} : syntax error, missing {top_symbol}")
            return lookahead, top_symbol, top_node, token_type, lexeme, "terminal insert"

    #  Unexpected symbol (should not occur)
    else:
        syntax_errors.append(f"#{line_number} : syntax error, Unexpected {lookahead}")
        return lookahead, top_symbol, top_node, token_type, lexeme, "unnormal symbol"


def parse():
    """LL(1) Table-driven Parser with Panic Mode error handling."""
    root = Node("Program")  # Root of the parse tree
    # stack will contain pairs, where the first element of each pair is the node's name and the second one is it's adress.
    parsstack = [("$", None), ("Program", root)]  # Stack holds tuples: (symbol, corresponding tree node)
    lookahead, token_type, lexeme, line_number = scanner.get_next_token()  # Get the first token
    agenda = None
    dollar_node = None  # Placeholder for the $ node
    flag = 0  # flag shows wheather we should modify the variables (needed if an error has occured) or we can simply pop from the stack and have our
    # normal routines.
    top_symbol = None
    top_node = None  # address of the top_symbol's node

    # we implement the logic stated on page 6 of the lecture note 5




    code_gen('type_specifier', 'void', -1)
    code_gen('put_id', 'output', -1)
    code_gen('fun_declaration', None, -1)
    code_gen('type_specifier', 'int', -1)
    code_gen('put_id', 'a', -1)
    code_gen('param_type_n_array', None, -1)
    code_gen('save_stack_frame', None, -1)
    interpret_code([
        'PRINT',
        get_var(-1, 'a')
    ])
    code_gen('fun_declaration_end', None, -1)


    while parsstack:

        if flag == 0:
            top_symbol, top_node = parsstack.pop()

        # as you see below, based on the agenda we make differnt desicions. details can be found on page 16th of the lecture note 5
        if flag == 1:

            if agenda == "EOF":
                #print("top symbol:",top_symbol )
                #print("look a head ",lookahead )
                #print("parsstack", parsstack)
                top_node.parent = None
                while parsstack:
                    top_symbol, top_node = parsstack.pop()
                    if top_symbol.startswith('#'):
                        code_gen(top_symbol[1:],  lexeme ,line_number)
                    else:
                        if(len(parsstack)==0):
                            break
                        top_node.parent = None

              
                return root

            elif agenda == "non-terminal insert":
                top_node.parent = None
                top_symbol, top_node = parsstack.pop()

            elif agenda == "terminal insert":
                top_node.parent = None
                top_symbol, top_node = parsstack.pop()

            elif agenda == "lookahead skip":
                lookahead, token_type, lexeme, line_number = scanner.get_next_token()

            else:
                lookahead, token_type, lexeme, line_number = scanner.get_next_token()

            flag = 0

        #  Terminal matches lookahead

        if top_symbol.startswith('#'):
            # Handle action symbol
            # next_symbol, next_node = stack.pop()
            # lookahead, token_type, lexeme, line_number = scanner.get_next_token()
            code_gen(top_symbol[1:],  lexeme ,line_number)
            continue  # Skip input consumption

        if top_symbol in cls:
            if top_symbol == "$":
                dollar_node = Node("$", parent=top_node)  # Create $ node but attach it later

            if top_symbol == lookahead:
                if top_symbol == "$":
                    dollar_node = Node("$", parent=top_node)  # Create $ node but attach it later

                elif top_node is not None and top_symbol not in {"$", "EOF"}:
                    # the name should be adjusted if top symbol is a terminal and match has happened.
                    top_node.name = f"({token_type}, {lexeme})"
                lookahead, token_type, lexeme, line_number = scanner.get_next_token()

            else:
                if top_symbol == "$":
                    break

                # Pass to panic mode recovery if terminal doesn't match
                lookahead, top_symbol, top_node, token_type, lexeme, agenda = panic_mode_recovery(parsstack, lookahead,
                                                                                                  line_number,
                                                                                                  top_symbol, top_node,
                                                                                                  token_type, lexeme)
                flag = 1
                continue


        # Non-terminal
        elif top_symbol in parsing_table and lookahead in parsing_table[top_symbol]:

            production_index = parsing_table[top_symbol][lookahead]

            # None valid produciton

            if production_index is None:

                lookahead, top_symbol, top_node, token_type, lexeme, agenda = panic_mode_recovery(parsstack, lookahead,
                                                                                                  line_number,
                                                                                                  top_symbol, top_node,
                                                                                                  token_type, lexeme)
                flag = 1
                continue

            # None valid produciton

            elif production_index == "synch":

                # Pass to panic mode recovery if the production is "synch"
                lookahead, top_symbol, top_node, token_type, lexeme, agenda = panic_mode_recovery(parsstack, lookahead,
                                                                                                  line_number,
                                                                                                  top_symbol, top_node,
                                                                                                  token_type, lexeme)
                flag = 1
                continue

            # valid produciton

            else:
                production = grammar[production_index]
                rhs = list(production.values())[0]  # we Get the RHS symbols as a list of strings
                if not rhs:  # handling Empty production
                    Node("epsilon", parent=top_node)
                else:
                    child_nodes = []  # Temporarily store child nodes
                    for symbol in rhs:
                        child_node = None
                        if symbol.startswith('#'):
                            child_nodes.append((symbol, None))

                        elif symbol in non_terminals:
                            child_node = Node(symbol, parent=top_node)
                            child_nodes.append((symbol, child_node))
                        else:
                            child_node = Node(f"({token_type}, {lexeme})", parent=top_node)
                            child_nodes.append((symbol, child_node))

                    # Push symbols onto the stack in reverse order for parsing
                    for symbol, child_node in reversed(child_nodes):
                        parsstack.append((symbol, child_node))

        #  No valid production
        else:

            lookahead, top_symbol, top_node, token_type, lexeme, agenda = panic_mode_recovery(parsstack, lookahead,
                                                                                              line_number)
            flag = 1
            continue

    # Attach the $ node at the end
    if dollar_node:
        dollar_node.parent = root

    return root


# funciton to write syntax errors to file
def write_syntax_errors_to_file():
    """Write syntax errors to a file."""
    with open("syntax_errors.txt", "w") as f:
        j = 0
        if syntax_errors:

            for error in syntax_errors:

                if j != 0:
                    f.write("\n")
                j = 1
                f.write(error)
        else:
            f.write("There is no syntax error.")



def main():
    """Main function to run the parser."""
    parse_tree = None
    try:
        parse_tree = parse()
        if parse_tree:
            print("Parsing completed successfully!")
        else:
            print("Parsing failed.")
    except Exception as e:
        print(f"Error: {e}")
    finally:
        write_syntax_errors_to_file()

    if parse_tree:
        with open("parse_tree.txt", "w", encoding="utf-8") as f:
            i=0
            
            #iterating over the tree to print it in the file
            for pre, _, node in RenderTree(parse_tree):
                if i !=0:
                    f.write(f"\n")
                i=1
                f.write(f"{pre}{node.name}")

        flush_outputs()




generated_code = []
#we divided memory into 3 parts. (0,5000) (5000,10000) (10000,...)
global_section = 5000
stack_section = 10000
global_section_ptr = global_section


def variable_interpret(var, i, stay_with_address=False):
    assert var[1] not in ['#@', '@#']
    #if variable var is in the stack and we have its address based on stack frame, then we calculate its global address.
    if '$' in var[1]:
        generated_code.append(["ADD",
                               runtime_address_stack_frame[2],
                               '#{}'.format(var[2]),
                               reserved_global_vars[i][2]
                               ])
        #if we want to accsess the element indirectly, then we use @var as an address of our main variable.
        if '@' in var[1]:
            generated_code.append(["ASSIGN",
                                   '@{}'.format(reserved_global_vars[i][2]),
                                   reserved_global_vars[i][2]
                                   ])
        if stay_with_address is False:
            return '@{}'.format(reserved_global_vars[i][2])
        return reserved_global_vars[i][2]
    return var[1] + str(var[2])


def interpret_code(code):
    code = code.copy()
    gen_code = [code[0]]
    for i in range(1, len(code)):
        gen_code.append(variable_interpret(code[i], i - 1))
    generated_code.append(gen_code)


def get_new_global_address(sz=1):
    global global_section_ptr
    global_section_ptr += 4 * sz
    return global_section_ptr - 4 * sz

#return free global address to use it as a temp variable
def get_new_global_tmp():
    address = get_new_global_address()
    interpret_code([
        'ASSIGN',
        ['', '#', stack_section],
        ['', '', address]
    ])
    return ["", "", address]


runtime_address_stack_ptr = get_new_global_tmp()
runtime_address_stack_frame = get_new_global_tmp()
reserved_global_vars = [get_new_global_tmp() for i in range(4)]

generated_code.append(['JP'])
main_starter_jump = len(generated_code) - 1


stack = []
global_action_table = {}
local_action_table = {}
local_function_name = None
runtime_stack_ptr = 0
saved_stack_frame = None
repeat = []

function_call_args = []


def get_new_stack_address(sz=1):
    global runtime_stack_ptr
    assert runtime_stack_ptr is not None
    # interpret_code([
    #     'ADD',
    #     ['', '#', 4 * sz],
    #     runtime_address_stack_ptr,
    #     runtime_address_stack_ptr
    # ])
    runtime_stack_ptr += sz * 4
    return runtime_stack_ptr - 4 * sz


# not complete
#return the address of given variable
def get_var(line_n, pid):
#if the given variable belongs to local variables, then return its address

    if pid in local_action_table:
        return local_action_table[pid]
#if the given variable belongs to global variables, then return its address
    elif pid in global_action_table:
        return global_action_table[pid]
#if there is not any variable with the given ID, then show semantic error
    else:
        scoping_error(line_n, pid)
        return [
            'NA', '', 0
        ]  # we return something meaningful enough to prevent errors ...

#returns a free cell in stack to use it as a temp variable
def get_new_stack_tmp():
    address = get_new_stack_address()
    return ["NA", "$", address]


# ['array', '$', 12]

def code_gen(routine_name, token, line_n):
    # print(routine_name, token, line_n)
    # generated_code.append(["++++++++++++++++++++++++", routine_name, token, line_n])
    global stack
    global global_action_table
    global local_action_table
    global local_function_name
    global runtime_stack_ptr
    global saved_stack_frame

    debug_mode = False
    debug_mode2 = False
    print(stack)
    #print(routine_name)
    #action symbol's subroutines
    if routine_name == 'type_specifier':
        stack.append(token)
    elif routine_name == 'put_id':
        if local_function_name is None:
            global_action_table[token] = list()
        else:
            local_action_table[token] = list()
        stack.append(token)
    elif routine_name == 'none_array_declaration':
        pid = stack.pop()
        tp = stack.pop()
        void_type_semantic_check(line_n, tp, pid)

        if pid in local_action_table:
            local_action_table[pid] = [tp, "$", get_new_stack_address()]
        else:
            global_action_table[pid] = [tp, "", get_new_global_address()]
    elif routine_name == 'array_declaration':
        pid = stack.pop()
        tp = stack.pop()
        void_type_semantic_check(line_n, tp, pid)

        if pid in local_action_table:
            address = get_new_stack_address(int(token))
            tmp = get_new_stack_tmp()
            generated_code.append([
                'ASSIGN',
                variable_interpret(['', '$', address], 1, stay_with_address=True),
                variable_interpret(tmp, 2)
            ])
            local_action_table[pid] = ["array", "$", tmp[2]]
        else:
            address = get_new_global_address(int(token))
            global_action_table[pid] = ["array", "#", address]
#declare function and add its record
    elif routine_name == 'fun_declaration':
        fname = stack.pop()
        return_tp = stack.pop()

        global_action_table[fname] = {'name':fname, 'return_type': return_tp, 'param': [], 'address': len(generated_code)}
        local_function_name = fname
        runtime_stack_ptr = 8  # first 8 bytes are reserved for return value and stack
        if debug_mode:
            generated_code.append(['PRINT', 5000])
            generated_code.append(['PRINT', 5004])
#reset all ther variables and arrays
    elif routine_name == 'fun_declaration_end':
        code_gen('return_void', None, line_n)
        local_action_table = {}
        local_function_name = None
        runtime_stack_ptr = 0
    elif routine_name == 'param_type_array':
        pid = stack.pop()
        tp = stack.pop()
        void_type_semantic_check(line_n, tp, pid)

        local_action_table[pid] = ["array", "$", runtime_stack_ptr]
        runtime_stack_ptr += 4
        global_action_table[local_function_name]['param'].append('array')
    elif routine_name == 'param_type_n_array':
        pid = stack.pop()
        tp = stack.pop()
        void_type_semantic_check(line_n, tp, pid)

        local_action_table[pid] = [tp, "$", runtime_stack_ptr]
        runtime_stack_ptr += 4
        global_action_table[local_function_name]['param'].append(tp)
    elif routine_name == 'main_starter':
        generated_code[main_starter_jump].append(len(generated_code))
        code_gen('pid', 'main', -2)
        code_gen('start_args', None, -2)
        code_gen('call_function', None, -2)
    elif routine_name == "save_stack_frame":
        saved_stack_frame = runtime_stack_ptr
        interpret_code(["ASSIGN",
                        runtime_address_stack_frame,
                        ['', '@', runtime_address_stack_ptr[2]]])
        interpret_code(["ASSIGN", runtime_address_stack_ptr, runtime_address_stack_frame])
        interpret_code(["SUB",
                        runtime_address_stack_frame,
                        ['', '#', runtime_stack_ptr],
                        runtime_address_stack_frame])
        get_new_stack_tmp()
#apply the operation, which has pushed into stack before, to operands
    elif routine_name == 'do_operation':
        tmp = get_new_stack_tmp()
        # print(stack[-3:])
        res = type_mismatch_check(stack[-1][0], stack[-3][0], line_n)
        interpret_code([
            stack[-2],
            stack[-3],
            stack[-1],
            tmp
        ])
        tmp[0] = res
        stack.pop()
        stack.pop()
        stack.pop()
        stack.append(tmp)
#push the operation which should be applied later into the stack
    elif routine_name == 'save_operation':
        if token == '+':
            stack.append('ADD')
        elif token == '-':
            stack.append('SUB')
        elif token == '*':
            stack.append('MULT')
        elif token == '/':
            stack.append('DIV')            
        elif token == '==':
            stack.append('EQ')
        elif token == '<':
            stack.append('LT')
#push ID token and its line into stack
    elif routine_name == 'pid':
        stack.append(get_var(line_n, token))
    elif routine_name == 'array_index':
        tmp = get_new_stack_tmp()
        interpret_code([
            'ADD',
            stack[-1],
            stack[-2],
            tmp
        ])
        # tmp2 = get_new_stack_tmp()
        # tmp[1] += '@'
        # interpret_code([
        #     'ASSIGN',
        #     tmp,
        #     tmp2
        # ])
        stack.pop()
        stack.pop()
        # stack.append(tmp2)
        stack.append(['int', '@$', tmp[2]])
    elif routine_name == 'assign':
        interpret_code([
            'ASSIGN',
            stack[-1],
            stack[-2]
        ])
        stack.pop()
#push NUM into stack
    elif routine_name == 'push':
        stack.append(['int', '#', str(token)])
    elif routine_name == 'start_args':
        function_call_args.append([])
#add top element of stack (argument of called function) to function's arguments array
    elif routine_name == 'fill_record':
        function_call_args[-1].append(stack.pop())
#pop called function's arguments and then check types of arguments and parameters.
#Consider 2 free memory cell for return value and return address.
#Assign each argument to its corresponding parameter.
    elif routine_name == 'call_function':
        f = stack.pop()
        # print(f)
        args = function_call_args.pop()
        args_check(f['param'], args, f['name'], line_n)

        return_value = get_new_stack_tmp()  # stack_frame

        tmp2 = runtime_stack_ptr

        return_address = get_new_stack_tmp()
        for arg in args:
            tmp = get_new_stack_tmp()
            # print("-----------", arg, tmp)
            interpret_code([
                'ASSIGN',
                arg,
                tmp
            ])
        interpret_code([
            'ADD',
            ['', '#', runtime_stack_ptr],
            runtime_address_stack_frame,
            runtime_address_stack_ptr
        ])
        interpret_code([
            'ASSIGN',
            ['', '', 0],
            return_address
        ])
        generated_code[-1][1] = '#{}'.format(len(generated_code) + 1)
        interpret_code([
            'JP',
            ['', '', f['address']]
        ])
        return_value[0] = f['return_type']
        stack.append(return_value)
        runtime_stack_ptr = tmp2
#adjust stack frame address and jump to where we called the function
    elif routine_name == 'return_void':
        interpret_code([
            'ADD',
            runtime_address_stack_frame,
            ['', '#', 4],
            runtime_address_stack_ptr
        ])
        interpret_code([
            'ASSIGN',
            ['', '$', 4],
            reserved_global_vars[3]
        ])
        interpret_code(["ASSIGN",
                        ['', '$', saved_stack_frame],
                        runtime_address_stack_frame
                        ])
        if debug_mode:
            generated_code.append(['PRINT', 5000])
            generated_code.append(['PRINT', 5004])
        interpret_code([
            'JP',
            ['', '@', reserved_global_vars[3][2]]
        ])
#adjust stack frame and assign return value(which is in the cell 4 of stack) to the global var which has been considered for the return value
    elif routine_name == 'return_value':
        interpret_code([
            'ASSIGN',
            stack.pop(),
            ['', '$', 0]
        ])
        interpret_code([
            'ADD',
            runtime_address_stack_frame,
            ['', '#', 4],
            runtime_address_stack_ptr
        ])
        interpret_code([
            'ASSIGN',
            ['', '$', 4],
            reserved_global_vars[3]
        ])
        interpret_code(["ASSIGN",
                        ['', '$', saved_stack_frame],
                        runtime_address_stack_frame
                        ])
        if debug_mode:
            generated_code.append(['PRINT', 5000])
            generated_code.append(['PRINT', 5004])
        interpret_code([
            'JP',
            ['', '@', reserved_global_vars[3][2]]
        ])
    elif routine_name == 'pop':
        stack.pop()
#if we have reached a break out of repeat block then detect it as a semantic error.otherwise, add it to the current repeat block array
    elif routine_name == 'save_break':
        interpret_code([
            "JP",
            ['', '', 0],
        ])
        if len(repeat) == 0:
            break_semantic_error(line_n)
        else:
            repeat[-1].append(len(generated_code) - 1)
#add JPF command and fill it with appropriate addrees later
    elif routine_name == 'save':
        interpret_code([
            "JPF",
            stack.pop(),  # stack(top)
            ['', '', 0],
        ])
        stack.append(['', '', len(generated_code) - 1])
    #determine jump address for JPF command   
    elif routine_name == 'jpf':
        generated_code[stack.pop()[2]][2] = (len(generated_code))
    #determine jump address for JPF command and save a block for JP command to fill later    
    elif routine_name == 'jpfw':
        generated_code[stack.pop()[2]][2] = (len(generated_code)+1)

    elif routine_name == 'jpf_save':
        generated_code[stack.pop()[2]][2] = len(generated_code) + 1  # i+1
        interpret_code([
            "JP",
            ['', '', 0],
        ])
        stack.append(['', '', len(generated_code) - 1])
     #determine jump address for JP command       
    elif routine_name == 'jp':
        generated_code[stack.pop()[2]][1] = len(generated_code)
    elif routine_name == 'label':
        stack.append(['', '', len(generated_code)])
        repeat.append([])
    elif routine_name == 'while':
        print(stack)
        interpret_code([
            "JP",
         stack.pop(),
        ])
        for br in repeat[-1]:
            generated_code[br][1] = len(generated_code)

       
    else:
        raise Exception("no such action symbol in code_gen()!")

    if debug_mode2:
        generated_code.append(["-------------------------{}".format(runtime_stack_ptr), routine_name, token, line_n])


def flush_outputs():
    semantic_errors_list = get_errors_list()

    semantic_errors_file = open("semantic_errors.txt", 'w')
    output_file = open("output.txt", 'w')

    if len(semantic_errors_list) > 0:
        output_file.write('The code has not been generated.\n')
        for err in semantic_errors_list:
            semantic_errors_file.write(err + '\n')
    else:
        semantic_errors_file.write('The input program is semantically correct.\n')
        i = 0
        for code in generated_code:
            while len(code) < 4:
                code.append('')
            output_file.write("{}\t({}, {}, {}, {})\n".format(i, code[0], code[1], code[2], code[3]))
            if code[0][0] not in '-+':
                i += 1

    semantic_errors_file.close()
    output_file.close()

semantic_errors_list = []


def get_errors_list():
    return semantic_errors_list

# return a semantic error when we reached a "break" outside a repeat block
def break_semantic_error(linen):


    semantic_errors_list.append(
        "#{} : Semantic Error! No 'repeat ... until' found for 'break'.".format(linen)
    )


def void_type_semantic_check(linen, tp, pid):


    global semantic_errors_list
    if tp == 'void':
        semantic_errors_list.append(
            "#{} : Semantic Error! Illegal type of void for '{}'.".format(linen, pid)
        )

#return a semantic error when we reached an undefined variable
def scoping_error(linen, pid):


    global semantic_errors_list
    semantic_errors_list.append(
        "#{} : Semantic Error! '{}' is not defined.".format(linen, pid)
    )

#return a semantic error when there is type mismatch between operands 
def type_mismatch_check(first_arg, second_arg, line_n):


    if first_arg != 'NA' and second_arg != 'NA' and first_arg != second_arg:
        semantic_errors_list.append(
            "#{} : Semantic Error! Type mismatch in operands, Got {} instead of {}.".format(line_n, first_arg,
                                                                                                second_arg)
        )
        return 'NA'
    return first_arg

#return a semantic error when there is a type mismatch between parameters and arguments of a function
def args_check(expected_args, input_args, fname, line_n):


    if len(expected_args) != len(input_args):
        semantic_errors_list.append(
            "#{} : Semantic Error! Mismatch in numbers of arguments of '{}'.".format(line_n, fname)
        )
    for i, (a, b) in enumerate(zip(expected_args, input_args)):
        b = b[0]
        if b != 'NA' and a != b:
            semantic_errors_list.append(
                "#{} : Semantic Error! Mismatch in type of argument {} of '{}'. Expected '{}' but got '{}' instead.".format(
                    line_n, i + 1, fname, a, b)
            )





if __name__ == "__main__":
    main()


